{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a jupyter notebook designed to run the full cell counting pipeline piece by piece to test each individual section. Full implementation of the pipeline can be found in FinalPipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'mean_x_value' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\turla\\Documents\\4. Uliege\\Semester 3\\Computer Vision\\Cell-detection-and-counting-Algorithms\\Pipeline\\FinalPipeline.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m image_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../Data/Input/15.tif\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m image_processor \u001b[39m=\u001b[39m ImageProcessor()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m results \u001b[39m=\u001b[39m image_processor\u001b[39m.\u001b[39;49mprocess_image(image_path)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m \u001b[39m# Append results to Droplet Positions and Cell Counts\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results:\n",
      "\u001b[1;32mc:\\Users\\turla\\Documents\\4. Uliege\\Semester 3\\Computer Vision\\Cell-detection-and-counting-Algorithms\\Pipeline\\FinalPipeline.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m image \u001b[39m=\u001b[39m tifffile\u001b[39m.\u001b[39mimread(image_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Apply your defined function to separate slices\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m slices, x_coordinates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49midentify_droplet_segments(image)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# Initialize an empty list to store cell counts and x coordinates\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m results \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32mc:\\Users\\turla\\Documents\\4. Uliege\\Semester 3\\Computer Vision\\Cell-detection-and-counting-Algorithms\\Pipeline\\FinalPipeline.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     full_segment \u001b[39m=\u001b[39m grey_image[segment_x[\u001b[39m0\u001b[39m]:segment_x[\u001b[39m1\u001b[39m], :][:, segments_y[\u001b[39m0\u001b[39m]:segments_y[\u001b[39m1\u001b[39m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     segments\u001b[39m.\u001b[39mappend(full_segment)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W5sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39mreturn\u001b[39;00m segments, mean_x_value\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'mean_x_value' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    " \n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, model_path='path_to_pretrained_model.pth'):\n",
    "        # Load the pretrained EfficientNet model\n",
    "        self.NN = EfficientNet.from_pretrained(\"efficientnet-b7\", advprop=False)\n",
    "\n",
    "        # Load the state dictionary of the custom model\n",
    "        #custom_model_state_dict = torch.load(model_path)\n",
    "\n",
    "        # Replace the classifier in the EfficientNet model with the custom classifier\n",
    "        #self.NN.classifier.load_state_dict(custom_model_state_dict['classifier'])\n",
    "\n",
    "        # Freeze the weights of the pre-trained model\n",
    "        for param in self.NN.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Assuming 'transform' is a torchvision.transforms object for preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  \n",
    "            transforms.RandomHorizontalFlip(0.4),\n",
    "            transforms.RandomVerticalFlip(0.4),\n",
    "            transforms.RandomInvert(0.7),\n",
    "            transforms.RandomRotation(35),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        # Load the image from the .tif file\n",
    "        image = tifffile.imread(image_path)\n",
    "\n",
    "        # Apply your defined function to separate slices\n",
    "        slices, x_coordinates = self.identify_droplet_segments(image)\n",
    "\n",
    "        # Initialize an empty list to store cell counts and x coordinates\n",
    "        results = []\n",
    "\n",
    "        # Iterate over slices and pass through the pretrained neural network\n",
    "        for i, slice in enumerate(slices):\n",
    "            input_tensor = self.transform(slice)\n",
    "            input_tensor = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.NN(input_tensor)\n",
    "\n",
    "            cell_count = output.item()\n",
    "\n",
    "            # Append results to the list\n",
    "            results.append({\"x_coordinate\": x_coordinates[i], \"cell_count\": cell_count})\n",
    "\n",
    "        return results\n",
    "\n",
    "    def identify_droplet_segments(self, image):\n",
    "\n",
    "        # 1. Convert the image to greyscale\n",
    "        grey_image = np.dot(image[..., :3], [0.299, 0.587, 0.114])\n",
    "\n",
    "        # 2. Apply filtering\n",
    "        sobel_filtered_image = self.sobel_filter(grey_image)\n",
    "\n",
    "        # 3. Apply slice on x to get a list of the slices\n",
    "        segments_x = self.slice_along_x(sobel_filtered_image)\n",
    "\n",
    "        #setup segments\n",
    "        segments = []\n",
    "\n",
    "        #loop through each x segment to get its y segment.\n",
    "        for segment_x in segments_x:\n",
    "            print(segment_x)\n",
    "            slice_y = grey_image[segment_x[0]:segment_x[1], :]\n",
    "            mean_x_value = np.mean(segment_x)\n",
    "            segments_y = self.slice_along_y(slice_y)\n",
    "            full_segment = grey_image[segment_x[0]:segment_x[1], :][:, segments_y[0]:segments_y[1]]\n",
    "            segments.append(full_segment)\n",
    "\n",
    "        return segments, mean_x_value\n",
    "\n",
    "    def sobel_filter(self, gray_arr):\n",
    "        # Apply Sobel filter to the image\n",
    "        sobel_x = cv2.Sobel(gray_arr, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(gray_arr, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        mask = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "        return mask\n",
    "\n",
    "    def slice_along_x(self, image, threshold_start=0.01, threshold_end=0.01, min_consecutive_frames=5,\n",
    "                  min_segment_length=400, max_segment_length=600):\n",
    "\n",
    "        # Calculate variance along the x-axis\n",
    "        x_variances = np.mean(image, axis=0)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold for at least min_consecutive_frames frames\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        consecutive_below_threshold = 0\n",
    "\n",
    "        for i, value in enumerate(x_variances):\n",
    "            if value > threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "                consecutive_below_threshold = 0\n",
    "            elif value <= threshold_end and droplet_started:\n",
    "                consecutive_below_threshold += 1\n",
    "                if consecutive_below_threshold >= min_consecutive_frames:\n",
    "                    droplet_started = False\n",
    "                    end_index = i - min_consecutive_frames\n",
    "                    segment_length = end_index - start_index\n",
    "\n",
    "                    # Check if the segment length is within the desired range\n",
    "                    if min_segment_length <= segment_length <= max_segment_length:\n",
    "                        segments.append((start_index, end_index))\n",
    "\n",
    "                    consecutive_below_threshold = 0\n",
    "\n",
    "        # If a droplet continues to the end of the image, consider it\n",
    "        if droplet_started:\n",
    "            end_index = len(x_variances) - 1\n",
    "            segment_length = end_index - start_index\n",
    "\n",
    "            # Check if the segment length is within the desired range\n",
    "            if min_segment_length <= segment_length <= max_segment_length:\n",
    "                segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        slices = [image[:, start:end] for start, end in segments]\n",
    "\n",
    "        return slices\n",
    "\n",
    "    def slice_along_y(self, image, y_threshold_start=0.01, y_threshold_end=0.01, min_consecutive_frames = 5):\n",
    "\n",
    "        # Calculate variance along the x-axis\n",
    "        y_variances = np.mean(image, axis=1)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold for at least min_consecutive_frames frames\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        consecutive_below_threshold = 0\n",
    "\n",
    "        for i, value in enumerate(y_variances):\n",
    "            if value > y_threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "                consecutive_below_threshold = 0\n",
    "            elif value <= y_threshold_end and droplet_started:\n",
    "                consecutive_below_threshold += 1\n",
    "                if consecutive_below_threshold >= min_consecutive_frames:\n",
    "                    droplet_started = False\n",
    "                    end_index = i - min_consecutive_frames\n",
    "                    segments.append((start_index, end_index))\n",
    "                    consecutive_below_threshold = 0\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        slices = [image[start:end, :] for start, end in segments]\n",
    "\n",
    "        return slices\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    inputPath = \"\"\n",
    "    outputPath = \"\"\n",
    "    DropletPositions = []\n",
    "    CellCounts = []\n",
    "\n",
    "    # TO ADD: for loop here, looping through each file in inputPath\n",
    "    image_path = \"../Data/Input/15.tif\"\n",
    "    image_processor = ImageProcessor()\n",
    "    results = image_processor.process_image(image_path)\n",
    "\n",
    "    # Append results to Droplet Positions and Cell Counts\n",
    "    for result in results:\n",
    "        DropletPositions.append(result[\"x_coordinate\"])\n",
    "        CellCounts.append(result[\"cell_count\"])\n",
    "\n",
    "    # After: Create a json file from DropletPositions and Cell Counts, Sequence Number, Frame Number\n",
    "    output_data = {\n",
    "        \"DropletPositions\": DropletPositions,\n",
    "        \"CellCounts\": CellCounts,\n",
    "        # Add other relevant information\n",
    "    }\n",
    "\n",
    "    # Save results to a .json file\n",
    "    with open('output.json', 'w') as json_file:\n",
    "        json.dump(output_data, json_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELEN0016",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
