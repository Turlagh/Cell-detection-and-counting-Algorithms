{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a jupyter notebook designed to run the full cell counting pipeline piece by piece to test each individual section. Full implementation of the pipeline can be found in FinalPipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "(0, 364) []\n",
      "(464, 1051) [(0, 457)]\n",
      "(1131, 1711) []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, model_path='path_to_pretrained_model.pth'):\n",
    "        # Load the pretrained EfficientNet model\n",
    "        self.NN = EfficientNet.from_pretrained(\"efficientnet-b7\", advprop=False)\n",
    "\n",
    "        # Load the state dictionary of the custom model\n",
    "        #custom_model_state_dict = torch.load(model_path)\n",
    "\n",
    "        # Replace the classifier in the EfficientNet model with the custom classifier\n",
    "        #self.NN.classifier.load_state_dict(custom_model_state_dict['classifier'])\n",
    "\n",
    "        # Freeze the weights of the pre-trained model\n",
    "        for param in self.NN.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Assuming 'transform' is a torchvision.transforms object for preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  \n",
    "            transforms.RandomHorizontalFlip(0.4),\n",
    "            transforms.RandomVerticalFlip(0.4),\n",
    "            transforms.RandomInvert(0.7),\n",
    "            transforms.RandomRotation(35),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        # Load the image from the .tif file\n",
    "        image = tifffile.imread(image_path)\n",
    "\n",
    "        # Apply your defined function to separate slices\n",
    "        droplet_segments, x_coordinates = self.identify_droplet_segments(image)\n",
    "\n",
    "        # Initialize an empty list to store cell counts and x coordinates\n",
    "        results = []\n",
    "\n",
    "        # Iterate over slices and pass through the pretrained neural network\n",
    "        for i, slice in enumerate(droplet_segments):\n",
    "            print(slice)\n",
    "            input_tensor = self.transform(slice)\n",
    "            input_tensor = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.NN(input_tensor)\n",
    "\n",
    "            cell_count = output.item()\n",
    "\n",
    "            # Append results to the list\n",
    "            results.append({\"x_coordinate\": x_coordinates[i], \"cell_count\": cell_count})\n",
    "\n",
    "        return results\n",
    "\n",
    "    def identify_droplet_segments(self, image):\n",
    "\n",
    "        # 1. Convert the image to greyscale\n",
    "        grey_image = np.dot(image[..., :3], [0.299, 0.587, 0.114])\n",
    "\n",
    "        # 2. Apply filtering\n",
    "        sobel_filtered_image = self.sobel_filter(grey_image)\n",
    "\n",
    "        # 3. Apply slice on x to get a list of the slices\n",
    "        segments_x = self.slice_along_x(sobel_filtered_image)\n",
    "\n",
    "        #setup segments\n",
    "        image_segments = []\n",
    "        mean_x_value = []\n",
    "\n",
    "        for segment_x in segments_x:\n",
    "            coordinates_y = self.slice_along_y(sobel_filtered_image, segment_x)\n",
    "            print(segment_x, coordinates_y)\n",
    "            image_segments = []\n",
    "            for coord_y in coordinates_y:\n",
    "                original_segment = image[segment_x[0]:segment_x[1], coord_y[0]:coord_y[1]]\n",
    "                image_segments.append(original_segment)\n",
    "\n",
    "        return image_segments, mean_x_value\n",
    "\n",
    "    def sobel_filter(self, gray_arr):\n",
    "        # Apply Sobel filter to the image\n",
    "        sobel_x = cv2.Sobel(gray_arr, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(gray_arr, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        mask = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "        return mask\n",
    "\n",
    "    def slice_along_x(self, image, threshold_start=45, threshold_end=45, min_segment_length=300, max_segment_length=600):\n",
    "\n",
    "        # Calculate variance along the x-axis\n",
    "        x_variances = np.mean(image, axis=0)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        start_index = 0\n",
    "\n",
    "        for i, value in enumerate(x_variances):\n",
    "            if value > threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "            elif value <= threshold_end and droplet_started:\n",
    "                droplet_started = False\n",
    "                end_index = i - 1\n",
    "                segment_length = end_index - start_index\n",
    "\n",
    "                # Check if the segment length is within the desired range\n",
    "                if min_segment_length <= segment_length <= max_segment_length:\n",
    "                    segments.append((start_index, end_index))\n",
    "\n",
    "        # If a droplet continues to the end of the image, consider it\n",
    "        if droplet_started:\n",
    "            end_index = len(x_variances) - 1\n",
    "            segment_length = end_index - start_index\n",
    "\n",
    "            # Check if the segment length is within the desired range\n",
    "            if min_segment_length <= segment_length <= max_segment_length:\n",
    "                segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        coordinates = [(start, end) for start, end in segments]\n",
    "\n",
    "        return coordinates\n",
    "\n",
    "    def slice_along_y(self, image, coordinates, y_threshold_start=40, y_threshold_end=40, min_segment_length=300, max_segment_length=600):\n",
    "\n",
    "        # Calculate variance along the x-axis\n",
    "        image = image[coordinates[0]:coordinates[1]]\n",
    "        y_variances = np.mean(image, axis=1)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        start_index = 0\n",
    "\n",
    "        for i, value in enumerate(y_variances):\n",
    "            if value > y_threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "            elif value <= y_threshold_end and droplet_started:\n",
    "                droplet_started = False\n",
    "                end_index = i - 1\n",
    "                segment_length = end_index - start_index\n",
    "\n",
    "                # Check if the segment length is within the desired range\n",
    "                if min_segment_length <= segment_length <= max_segment_length:\n",
    "                    segments.append((start_index, end_index))\n",
    "\n",
    "        # If a droplet continues to the end of the image, consider it\n",
    "        if droplet_started:\n",
    "            end_index = len(y_variances) - 1\n",
    "            segment_length = end_index - start_index\n",
    "\n",
    "            # Check if the segment length is within the desired range\n",
    "            if min_segment_length <= segment_length <= max_segment_length:\n",
    "                segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        coordinates_y = [(start, end) for start, end in segments]\n",
    "\n",
    "        return coordinates_y\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    inputPath = \"\"\n",
    "    outputPath = \"\"\n",
    "    DropletPositions = []\n",
    "    CellCounts = []\n",
    "\n",
    "    # TO ADD: for loop here, looping through each file in inputPath\n",
    "    image_path = \"../Data/Input/15.tif\"\n",
    "    image_processor = ImageProcessor()\n",
    "    results = image_processor.process_image(image_path)\n",
    "\n",
    "    # Append results to Droplet Positions and Cell Counts\n",
    "    for result in results:\n",
    "        DropletPositions.append(result[\"x_coordinate\"])\n",
    "        CellCounts.append(result[\"cell_count\"])\n",
    "\n",
    "    # After: Create a json file from DropletPositions and Cell Counts, Sequence Number, Frame Number\n",
    "    output_data = {\n",
    "        \"DropletPositions\": DropletPositions,\n",
    "        \"CellCounts\": CellCounts,\n",
    "        # Add other relevant information\n",
    "    }\n",
    "\n",
    "    # Save results to a .json file\n",
    "    with open('output.json', 'w') as json_file:\n",
    "        json.dump(output_data, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "class SegmentationAndRegressionModel(nn.Module):\n",
    "    def __init__(self, encoder_name=\"efficientnet-b0\", encoder_weights=\"imagenet\"):\n",
    "        super(SegmentationAndRegressionModel, self).__init__()\n",
    "        self.unet = smp.Unet(encoder_name, encoder_weights=encoder_weights, in_channels=1, classes=1)\n",
    "        for param in self.unet.parameters(): #freeze params for speed\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(16384, 512), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        seg_output = self.unet(x)\n",
    "        mlp_input = seg_output.view(seg_output.size(0), -1)  # Flatten\n",
    "        regression_output = self.mlp(mlp_input)\n",
    "        return regression_output\n",
    "\n",
    "\n",
    "    \n",
    "class ImageProcessor:\n",
    "    def __init__(self, model_path='../Data/model_efficientNetB7.pt'):\n",
    "        # Load the cell count model\n",
    "        self.segmentation_and_regression_model = SegmentationAndRegressionModel()\n",
    "        state_dict = torch.load(model_path)\n",
    "        self.segmentation_and_regression_model.load_state_dict(state_dict)\n",
    "        self.segmentation_and_regression_model.eval()\n",
    "       \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),  \n",
    "            transforms.Resize((128, 128)),  # Resize the image for consistant input shape\n",
    "            transforms.ToTensor(), \n",
    "        ])\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        # Load the image from the .tif file\n",
    "        image = tifffile.imread(image_path)\n",
    "\n",
    "        # Apply your defined function to separate slices\n",
    "        droplet_segments, x_coordinates = self.identify_droplet_segments(image)\n",
    "\n",
    "        # Initialize an empty list to store cell counts and x coordinates\n",
    "        results = []\n",
    "\n",
    "        # Iterate over slices and pass through the pretrained neural network\n",
    "        for i, slice in enumerate(droplet_segments):\n",
    "            droplet_segment_tensor = self.transform(slice)\n",
    "            print(droplet_segment_tensor)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output_cell_count = self.segmentation_and_regression_model(droplet_segment_tensor)\n",
    "\n",
    "            # Extract ouput\n",
    "            cell_count = torch.sum(output_cell_count).item()\n",
    "\n",
    "            # Append results to the list\n",
    "            results.append({\"x_coordinate\": x_coordinates[i], \"cell_count\": cell_count})\n",
    "\n",
    "            return results\n",
    "\n",
    "    def identify_droplet_segments(self, image):\n",
    "\n",
    "        # 1. Convert the image to greyscale\n",
    "        grey_image = np.dot(image[..., :3], [0.299, 0.587, 0.114])\n",
    "\n",
    "        # 2. Apply filtering\n",
    "        sobel_filtered_image = self.sobel_filter(grey_image)\n",
    "\n",
    "        # 3. Apply slice on x to get a list of the slices\n",
    "        segments_x = self.slice_along_x(sobel_filtered_image)\n",
    "\n",
    "        # setup segments\n",
    "        image_segments = []\n",
    "        mean_x_value = []\n",
    "\n",
    "        for segment_x in segments_x:\n",
    "            coordinates_y = self.slice_along_y(image = sobel_filtered_image, coordinates= segment_x)\n",
    "            original_segment = grey_image[coordinates_y[0][0]:coordinates_y[0][1],segment_x[0]:segment_x[1]]\n",
    "            original_segment = original_segment.astype(int)\n",
    "            self.visualize_image(original_segment)\n",
    "            image_segments.append(original_segment)\n",
    "\n",
    "        return image_segments, mean_x_value\n",
    "\n",
    "    def visualize_image(self, image):\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    def sobel_filter(self, gray_arr):\n",
    "        # Apply Sobel filter to the image\n",
    "        sobel_x = cv2.Sobel(gray_arr, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(gray_arr, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        mask = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "        return mask\n",
    "\n",
    "    def slice_along_x(self, image, threshold_start=40, threshold_end=40, min_segment_length=500, max_segment_length=800):\n",
    "        # Calculate variance along the x-axis\n",
    "        x_variances = np.mean(image, axis=0)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        start_index = 0\n",
    "\n",
    "        for i, value in enumerate(x_variances):\n",
    "            if value > threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "            elif value <= threshold_end and droplet_started:\n",
    "                droplet_started = False\n",
    "                end_index = i - 1\n",
    "                segment_length = end_index - start_index\n",
    "\n",
    "                # Check if the segment length is within the desired range\n",
    "                if min_segment_length <= segment_length <= max_segment_length:\n",
    "                    segments.append((start_index, end_index))\n",
    "\n",
    "        # If a droplet continues to the end of the image, consider it\n",
    "        if droplet_started:\n",
    "            end_index = len(x_variances) - 1\n",
    "            segment_length = end_index - start_index\n",
    "\n",
    "            # Check if the segment length is within the desired range\n",
    "            if min_segment_length <= segment_length <= max_segment_length:\n",
    "                segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        coordinates = [(start, end) for start, end in segments]\n",
    "\n",
    "        return coordinates\n",
    "\n",
    "    def slice_along_y(self, image, coordinates, y_threshold_start=40, y_threshold_end=40,\n",
    "                      min_segment_length=450, max_segment_length=800):\n",
    "        # Calculate variance along the x-axis\n",
    "        image = image[:,coordinates[0]:coordinates[1]]\n",
    "        y_variances = np.mean(image, axis=1)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        start_index = 0\n",
    "\n",
    "        for i, value in enumerate(y_variances):\n",
    "            if value > y_threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "            elif value <= y_threshold_end and droplet_started:\n",
    "                droplet_started = False\n",
    "                end_index = i - 1\n",
    "                segment_length = end_index - start_index\n",
    "\n",
    "                # Check if the segment length is within the desired range\n",
    "                if min_segment_length <= segment_length <= max_segment_length:\n",
    "                    segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        coordinates_y = [(start, end) for start, end in segments]\n",
    "\n",
    "        return coordinates_y\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    inputPath = \"\"\n",
    "    outputPath = \"\"\n",
    "    DropletPositions = []\n",
    "    CellCounts = []\n",
    "\n",
    "    # TO ADD: for loop here, looping through each file in inputPath\n",
    "    image_path = \"../Data/Input/15.tif\"\n",
    "    image_processor = ImageProcessor()\n",
    "    results = image_processor.process_image(image_path)\n",
    "\n",
    "    # Append results to Droplet Positions and Cell Counts\n",
    "    for result in results:\n",
    "        DropletPositions.append(result[\"x_coordinate\"])\n",
    "        CellCounts.append(result[\"cell_count\"])\n",
    "\n",
    "\n",
    "    # After: Create a json file from DropletPositions and Cell Counts, Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\turla\\Documents\\4. Uliege\\Semester 3\\Computer Vision\\Cell-detection-and-counting-Algorithms\\Pipeline\\FinalPipeline.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=185'>186</a>\u001b[0m \u001b[39m# TO ADD: for loop here, looping through each file in inputPath\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=186'>187</a>\u001b[0m image_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../Data/Input/15.tif\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=187'>188</a>\u001b[0m image_processor \u001b[39m=\u001b[39m ImageProcessor()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m results \u001b[39m=\u001b[39m image_processor\u001b[39m.\u001b[39mprocess_image(image_path)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=190'>191</a>\u001b[0m \u001b[39m# Append results to Droplet Positions and Cell Counts\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\turla\\Documents\\4. Uliege\\Semester 3\\Computer Vision\\Cell-detection-and-counting-Algorithms\\Pipeline\\FinalPipeline.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../Data/model_efficientNetB7.pt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m# Load the cell count model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegmentation_and_regression_model \u001b[39m=\u001b[39m NN\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(model_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegmentation_and_regression_model\u001b[39m.\u001b[39mload_state_dict(state_dict)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/turla/Documents/4.%20Uliege/Semester%203/Computer%20Vision/Cell-detection-and-counting-Algorithms/Pipeline/FinalPipeline.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msegmentation_and_regression_model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\turla\\.conda\\envs\\ELEN0016\\lib\\site-packages\\torch\\serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m-> 1014\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[0;32m   1015\u001b[0m                      map_location,\n\u001b[0;32m   1016\u001b[0m                      pickle_module,\n\u001b[0;32m   1017\u001b[0m                      overall_storage\u001b[39m=\u001b[39moverall_storage,\n\u001b[0;32m   1018\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1019\u001b[0m \u001b[39mif\u001b[39;00m mmap:\n\u001b[0;32m   1020\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmmap can only be used with files saved with \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1021\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1022\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\turla\\.conda\\envs\\ELEN0016\\lib\\site-packages\\torch\\serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1420\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1421\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[1;32m-> 1422\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1424\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1425\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1426\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtorch.load.metadata\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mserialization_id\u001b[39m\u001b[39m\"\u001b[39m: zip_file\u001b[39m.\u001b[39mserialization_id()}\n\u001b[0;32m   1427\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\turla\\.conda\\envs\\ELEN0016\\lib\\site-packages\\torch\\serialization.py:1392\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1391\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1392\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[0;32m   1394\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\turla\\.conda\\envs\\ELEN0016\\lib\\site-packages\\torch\\serialization.py:1366\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         storage\u001b[39m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1363\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1366\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[0;32m   1367\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1368\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1371\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\turla\\.conda\\envs\\ELEN0016\\lib\\site-packages\\torch\\serialization.py:381\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    380\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 381\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[0;32m    382\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    383\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\turla\\.conda\\envs\\ELEN0016\\lib\\site-packages\\torch\\serialization.py:274\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    273\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 274\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[0;32m    275\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    276\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[1;32mc:\\Users\\turla\\.conda\\envs\\ELEN0016\\lib\\site-packages\\torch\\serialization.py:258\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    255\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    259\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    260\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    261\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    262\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    263\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "\"\"\"\"\"\"\n",
    "NN = models.efficientnet_b7(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "#resnet not trained later \n",
    "for param in NN.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_features = NN.classifier[-1].in_features\n",
    "    \n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(512, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(64, 1),\n",
    "    #nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "NN.classifier = mlp\n",
    "    \n",
    "class ImageProcessor:\n",
    "    def __init__(self, model_path='../Data/model_efficientNetB7.pt'):\n",
    "        # Load the cell count model\n",
    "        self.segmentation_and_regression_model = NN\n",
    "        state_dict = torch.load(model_path)\n",
    "        self.segmentation_and_regression_model.load_state_dict(state_dict)\n",
    "        self.segmentation_and_regression_model.eval()\n",
    "       \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),  \n",
    "            transforms.Resize((128, 128)),  # Resize the image for consistant input shape\n",
    "            transforms.ToTensor(), \n",
    "        ])\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        # Load the image from the .tif file\n",
    "        image = tifffile.imread(image_path)\n",
    "\n",
    "        # Apply your defined function to separate slices\n",
    "        droplet_segments, x_coordinates = self.identify_droplet_segments(image)\n",
    "\n",
    "        # Initialize an empty list to store cell counts and x coordinates\n",
    "        results = []\n",
    "\n",
    "        # Iterate over slices and pass through the pretrained neural network\n",
    "        for i, slice in enumerate(droplet_segments):\n",
    "            print(slice)\n",
    "            droplet_segment = cv2.resize(slice, (128,128), interpolation = cv2.INTER_LINEAR)\n",
    "            droplet_segment_tensor = torch.from_numpy(droplet_segment)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output_cell_count = self.segmentation_and_regression_model(droplet_segment_tensor)\n",
    "\n",
    "            # Extract ouput\n",
    "            cell_count = torch.sum(output_cell_count).item()\n",
    "\n",
    "            # Append results to the list\n",
    "            results.append({\"x_coordinate\": x_coordinates[i], \"cell_count\": cell_count})\n",
    "\n",
    "            return results\n",
    "\n",
    "    def identify_droplet_segments(self, image):\n",
    "\n",
    "        # 1. Convert the image to greyscale\n",
    "        grey_image = np.dot(image[..., :3], [0.299, 0.587, 0.114])\n",
    "\n",
    "        # 2. Apply filtering\n",
    "        sobel_filtered_image = self.sobel_filter(grey_image)\n",
    "\n",
    "        # 3. Apply slice on x to get a list of the slices\n",
    "        segments_x = self.slice_along_x(sobel_filtered_image)\n",
    "\n",
    "        # setup segments\n",
    "        image_segments = []\n",
    "        mean_x_value = []\n",
    "\n",
    "        for segment_x in segments_x:\n",
    "            coordinates_y = self.slice_along_y(image = sobel_filtered_image, coordinates= segment_x)\n",
    "            original_segment = grey_image[coordinates_y[0][0]:coordinates_y[0][1],segment_x[0]:segment_x[1]]\n",
    "            original_segment = original_segment.astype(int)\n",
    "            self.visualize_image(original_segment)\n",
    "            image_segments.append(original_segment)\n",
    "\n",
    "        return image_segments, mean_x_value\n",
    "\n",
    "    def visualize_image(self, image):\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    def sobel_filter(self, gray_arr):\n",
    "        # Apply Sobel filter to the image\n",
    "        sobel_x = cv2.Sobel(gray_arr, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(gray_arr, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        mask = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "        return mask\n",
    "\n",
    "    def slice_along_x(self, image, threshold_start=40, threshold_end=40, min_segment_length=500, max_segment_length=800):\n",
    "        # Calculate variance along the x-axis\n",
    "        x_variances = np.mean(image, axis=0)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        start_index = 0\n",
    "\n",
    "        for i, value in enumerate(x_variances):\n",
    "            if value > threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "            elif value <= threshold_end and droplet_started:\n",
    "                droplet_started = False\n",
    "                end_index = i - 1\n",
    "                segment_length = end_index - start_index\n",
    "\n",
    "                # Check if the segment length is within the desired range\n",
    "                if min_segment_length <= segment_length <= max_segment_length:\n",
    "                    segments.append((start_index, end_index))\n",
    "\n",
    "        # If a droplet continues to the end of the image, consider it\n",
    "        if droplet_started:\n",
    "            end_index = len(x_variances) - 1\n",
    "            segment_length = end_index - start_index\n",
    "\n",
    "            # Check if the segment length is within the desired range\n",
    "            if min_segment_length <= segment_length <= max_segment_length:\n",
    "                segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        coordinates = [(start, end) for start, end in segments]\n",
    "\n",
    "        return coordinates\n",
    "\n",
    "    def slice_along_y(self, image, coordinates, y_threshold_start=40, y_threshold_end=40,\n",
    "                      min_segment_length=450, max_segment_length=800):\n",
    "        # Calculate variance along the x-axis\n",
    "        image = image[:,coordinates[0]:coordinates[1]]\n",
    "        y_variances = np.mean(image, axis=1)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        start_index = 0\n",
    "\n",
    "        for i, value in enumerate(y_variances):\n",
    "            if value > y_threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "            elif value <= y_threshold_end and droplet_started:\n",
    "                droplet_started = False\n",
    "                end_index = i - 1\n",
    "                segment_length = end_index - start_index\n",
    "\n",
    "                # Check if the segment length is within the desired range\n",
    "                if min_segment_length <= segment_length <= max_segment_length:\n",
    "                    segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        coordinates_y = [(start, end) for start, end in segments]\n",
    "\n",
    "        return coordinates_y\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    inputPath = \"\"\n",
    "    outputPath = \"\"\n",
    "    DropletPositions = []\n",
    "    CellCounts = []\n",
    "\n",
    "    # TO ADD: for loop here, looping through each file in inputPath\n",
    "    image_path = \"../Data/Input/15.tif\"\n",
    "    image_processor = ImageProcessor()\n",
    "    results = image_processor.process_image(image_path)\n",
    "\n",
    "    # Append results to Droplet Positions and Cell Counts\n",
    "    for result in results:\n",
    "        DropletPositions.append(result[\"x_coordinate\"])\n",
    "        CellCounts.append(result[\"cell_count\"])\n",
    "\n",
    "\n",
    "    # After: Create a json file from DropletPositions and Cell Counts, Sequence\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELEN0016",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
