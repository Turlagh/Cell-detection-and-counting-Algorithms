{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "\"\"\"\"\"\"\n",
    "NN = models.efficientnet_b7(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "#resnet not trained later \n",
    "for param in NN.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_features = NN.classifier[-1].in_features\n",
    "    \n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(512, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(64, 1),\n",
    "    #nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "NN.classifier = mlp\n",
    "    \n",
    "class ImageProcessor:\n",
    "    def __init__(self, model_path='../Data/model_efficientNetB7.pt'):\n",
    "        # Load the cell count model\n",
    "        self.segmentation_and_regression_model = NN\n",
    "        state_dict = torch.load(model_path)\n",
    "        self.segmentation_and_regression_model.load_state_dict(state_dict)\n",
    "        self.segmentation_and_regression_model.eval()\n",
    "       \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),  \n",
    "            transforms.Resize((128, 128)),  # Resize the image for consistant input shape\n",
    "            transforms.ToTensor(), \n",
    "        ])\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        # Load the image from the .tif file\n",
    "        image = tifffile.imread(image_path)\n",
    "\n",
    "        # Apply your defined function to separate slices\n",
    "        droplet_segments, x_coordinates = self.identify_droplet_segments(image)\n",
    "\n",
    "        # Initialize an empty list to store cell counts and x coordinates\n",
    "        results = []\n",
    "\n",
    "        # Iterate over slices and pass through the pretrained neural network\n",
    "        for i, slice in enumerate(droplet_segments):\n",
    "            print(slice)\n",
    "            droplet_segment = cv2.resize(slice, (128,128), interpolation = cv2.INTER_LINEAR)\n",
    "            droplet_segment_tensor = torch.from_numpy(droplet_segment)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output_cell_count = self.segmentation_and_regression_model(droplet_segment_tensor)\n",
    "\n",
    "            # Extract ouput\n",
    "            cell_count = torch.sum(output_cell_count).item()\n",
    "\n",
    "            # Append results to the list\n",
    "            results.append({\"x_coordinate\": x_coordinates[i], \"cell_count\": cell_count})\n",
    "\n",
    "            return results\n",
    "\n",
    "    def identify_droplet_segments(self, image):\n",
    "\n",
    "        # 1. Convert the image to greyscale\n",
    "        grey_image = np.dot(image[..., :3], [0.299, 0.587, 0.114])\n",
    "\n",
    "        # 2. Apply filtering\n",
    "        canny_filtered_image = self.canny_filter(grey_image)\n",
    "\n",
    "        # 3. Apply slice on x to get a list of the slices\n",
    "        segments_x = self.slice_along_x(canny_filtered_image)\n",
    "\n",
    "        # setup segments\n",
    "        image_segments = []\n",
    "        mean_x_value = []\n",
    "\n",
    "        for segment_x in segments_x:\n",
    "            coordinates_y = self.slice_along_y(image = canny_filtered_image, coordinates= segment_x)\n",
    "            original_segment = grey_image[coordinates_y[0][0]:coordinates_y[0][1],segment_x[0]:segment_x[1]]\n",
    "            original_segment = original_segment.astype(int)\n",
    "            self.visualize_image(original_segment)\n",
    "            image_segments.append(original_segment)\n",
    "\n",
    "        return image_segments, mean_x_value\n",
    "\n",
    "    def visualize_image(self, image):\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    def canny_filter(self, gray_arr):\n",
    "        # Replace Sobel filter with Canny edge detection\n",
    "        edges = cv2.Canny(gray_arr.astype(np.uint8), 50, 150)  # You may need to adjust the threshold values\n",
    "\n",
    "        return edges\n",
    "\n",
    "    def slice_along_x(self, image, threshold_start=40, threshold_end=40, min_segment_length=500, max_segment_length=800):\n",
    "        # Calculate variance along the x-axis\n",
    "        x_variances = np.mean(image, axis=0)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        start_index = 0\n",
    "\n",
    "        for i, value in enumerate(x_variances):\n",
    "            if value > threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "            elif value <= threshold_end and droplet_started:\n",
    "                droplet_started = False\n",
    "                end_index = i - 1\n",
    "                segment_length = end_index - start_index\n",
    "\n",
    "                # Check if the segment length is within the desired range\n",
    "                if min_segment_length <= segment_length <= max_segment_length:\n",
    "                    segments.append((start_index, end_index))\n",
    "\n",
    "        # If a droplet continues to the end of the image, consider it\n",
    "        if droplet_started:\n",
    "            end_index = len(x_variances) - 1\n",
    "            segment_length = end_index - start_index\n",
    "\n",
    "            # Check if the segment length is within the desired range\n",
    "            if min_segment_length <= segment_length <= max_segment_length:\n",
    "                segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        coordinates = [(start, end) for start, end in segments]\n",
    "\n",
    "        return coordinates\n",
    "\n",
    "    def slice_along_y(self, image, coordinates, y_threshold_start=40, y_threshold_end=40,\n",
    "                      min_segment_length=450, max_segment_length=800):\n",
    "        # Calculate variance along the x-axis\n",
    "        image = image[:,coordinates[0]:coordinates[1]]\n",
    "        y_variances = np.mean(image, axis=1)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        start_index = 0\n",
    "\n",
    "        for i, value in enumerate(y_variances):\n",
    "            if value > y_threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "            elif value <= y_threshold_end and droplet_started:\n",
    "                droplet_started = False\n",
    "                end_index = i - 1\n",
    "                segment_length = end_index - start_index\n",
    "\n",
    "                # Check if the segment length is within the desired range\n",
    "                if min_segment_length <= segment_length <= max_segment_length:\n",
    "                    segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        coordinates_y = [(start, end) for start, end in segments]\n",
    "\n",
    "        return coordinates_y\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    inputPath = \"\"\n",
    "    outputPath = \"\"\n",
    "    DropletPositions = []\n",
    "    CellCounts = []\n",
    "\n",
    "    # TO ADD: for loop here, looping through each file in inputPath\n",
    "    image_path = \"../Data/Input/15.tif\"\n",
    "    image_processor = ImageProcessor()\n",
    "    results = image_processor.process_image(image_path)\n",
    "\n",
    "    # Append results to Droplet Positions and Cell Counts\n",
    "    for result in results:\n",
    "        DropletPositions.append(result[\"x_coordinate\"])\n",
    "        CellCounts.append(result[\"cell_count\"])\n",
    "\n",
    "\n",
    "    # After: Create a json file from DropletPositions and Cell Counts, Sequence\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
