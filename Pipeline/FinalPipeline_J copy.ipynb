{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a jupyter notebook designed to run the full cell counting pipeline piece by piece to test each individual section. Full implementation of the pipeline can be found in FinalPipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No droplet segments detected in 12.tif. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No droplet segments detected in 19.tif. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No droplet segments detected in 21.tif. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No droplet segments detected in 26.tif. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No droplet segments detected in 28.tif. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No droplet segments detected in 33.tif. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No droplet segments detected in 38.tif. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No droplet segments detected in 40.tif. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, model_path='model_efficientNetB7Finetune2_17.pt'):\n",
    "        # Load the cell count model\n",
    "        \n",
    "        NN = models.efficientnet_b7(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "        #resnet not trained later \n",
    "        for param in NN.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        num_features = NN.classifier[-1].in_features\n",
    "\n",
    "        mlp = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            #nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        NN.classifier = mlp\n",
    "\n",
    "        NN = NN.to(device)\n",
    "        \n",
    "        \n",
    "        self.segmentation_and_regression_model = NN\n",
    "        state_dict = torch.load(model_path, map_location = device)\n",
    "        self.segmentation_and_regression_model.load_state_dict(state_dict)\n",
    "        self.segmentation_and_regression_model.eval()\n",
    "       \n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        # Load the image from the .tif file\n",
    "        image = tifffile.imread(image_path)\n",
    "\n",
    "        # Apply your defined function to separate slices\n",
    "        droplet_segments, x_coordinates = self.identify_droplet_segments(image)\n",
    "\n",
    "        # Initialize an empty list to store cell counts and x coordinates\n",
    "        results = []\n",
    "        droplet_segment_prelist = []\n",
    "\n",
    "        # Iterate over slices and pass through the pretrained neural network\n",
    "        for i, slice in enumerate(droplet_segments):\n",
    "            slice = slice.astype(np.uint8)\n",
    "            droplet_segment =  cv2.resize(slice, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "            droplet_segment = np.tile(droplet_segment[np.newaxis, np.newaxis, :, :], (1,3,1,1))\n",
    "            droplet_segment_tensor = torch.from_numpy(droplet_segment) / 255\n",
    "            droplet_segment_tensor = droplet_segment_tensor.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output_cell_count = self.segmentation_and_regression_model(droplet_segment_tensor)\n",
    "\n",
    "            # Extract ouput\n",
    "            cell_count = output_cell_count.item()\n",
    "\n",
    "            # Append results to the list\n",
    "            results.append({\"x_coordinate\": x_coordinates[i], \"cell_count\": cell_count})\n",
    "            droplet_segment_prelist.append(droplet_segment_tensor)\n",
    "\n",
    "        return results, droplet_segment_prelist\n",
    "\n",
    "    def identify_droplet_segments(self, image):\n",
    "\n",
    "        # 1. Convert the image to greyscale\n",
    "        grey_image = image[:, :, 0]\n",
    "\n",
    "        # 2. Apply filtering\n",
    "        sobel_filtered_image = self.sobel_filter(grey_image)\n",
    "\n",
    "        # 3. Apply slice on x to get a list of the slices\n",
    "        segments_x = self.slice_along_x(sobel_filtered_image)\n",
    "\n",
    "        # setup segments\n",
    "        image_segments = []\n",
    "        mean_x_value = []\n",
    "\n",
    "        for segment_x in segments_x:\n",
    "            coordinates_y = self.slice_along_y(image = sobel_filtered_image, coordinates= segment_x)\n",
    "            original_segment = grey_image[coordinates_y[0][0]:coordinates_y[0][1],segment_x[0]:segment_x[1]]\n",
    "            original_segment = original_segment.astype(int)\n",
    "            #self.visualize_image(original_segment)\n",
    "            image_segments.append(original_segment)\n",
    "            mean_x_value.append(np.mean(segment_x))\n",
    "\n",
    "        return image_segments, mean_x_value\n",
    "\n",
    "    def visualize_image(self, image):\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    def sobel_filter(self, gray_arr):\n",
    "        # Apply Sobel filter to the image\n",
    "        sobel_x = cv2.Sobel(gray_arr, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(gray_arr, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        mask = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "        return mask\n",
    "\n",
    "    def slice_along_x(self, image, threshold_start=40, threshold_end=40, min_segment_length=500, max_segment_length=800):\n",
    "        # Calculate variance along the x-axis\n",
    "        x_variances = np.mean(image, axis=0)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        start_index = 0\n",
    "\n",
    "        for i, value in enumerate(x_variances):\n",
    "            if value > threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "            elif value <= threshold_end and droplet_started:\n",
    "                droplet_started = False\n",
    "                end_index = i - 1\n",
    "                segment_length = end_index - start_index\n",
    "\n",
    "                # Check if the segment length is within the desired range\n",
    "                if min_segment_length <= segment_length <= max_segment_length:\n",
    "                    segments.append((start_index, end_index))\n",
    "\n",
    "        # If a droplet continues to the end of the image, consider it\n",
    "        if droplet_started:\n",
    "            end_index = len(x_variances) - 1\n",
    "            segment_length = end_index - start_index\n",
    "\n",
    "            # Check if the segment length is within the desired range\n",
    "            if min_segment_length <= segment_length <= max_segment_length:\n",
    "                segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        coordinates = [(start, end) for start, end in segments]\n",
    "\n",
    "        return coordinates\n",
    "\n",
    "    def slice_along_y(self, image, coordinates, y_threshold_start=40, y_threshold_end=40,\n",
    "                      min_segment_length=450, max_segment_length=800):\n",
    "        # Calculate variance along the x-axis\n",
    "        image = image[:,coordinates[0]:coordinates[1]]\n",
    "        y_variances = np.mean(image, axis=1)\n",
    "\n",
    "        # Identify segments where the variance exceeds the threshold\n",
    "        segments = []\n",
    "        droplet_started = False\n",
    "        start_index = 0\n",
    "\n",
    "        for i, value in enumerate(y_variances):\n",
    "            if value > y_threshold_start and not droplet_started:\n",
    "                droplet_started = True\n",
    "                start_index = i\n",
    "            elif value <= y_threshold_end and droplet_started:\n",
    "                droplet_started = False\n",
    "                end_index = i - 1\n",
    "                segment_length = end_index - start_index\n",
    "\n",
    "                # Check if the segment length is within the desired range\n",
    "                if min_segment_length <= segment_length <= max_segment_length:\n",
    "                    segments.append((start_index, end_index))\n",
    "\n",
    "        # Extract slices based on the identified positions\n",
    "        coordinates_y = [(start, end) for start, end in segments]\n",
    "\n",
    "        return coordinates_y\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    inputPath = \"../Data/Input\"\n",
    "    outputPath = \"../Data/Output\"\n",
    "    \n",
    "    # Initialize lists to store results for each frame\n",
    "    all_results = []\n",
    "    droplet_segment_tensors_list = []\n",
    "\n",
    "    # Iterate through each file in inputPath\n",
    "    for filename in os.listdir(inputPath):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            image_path = os.path.join(inputPath, filename)\n",
    "\n",
    "            # Process each image\n",
    "            image_processor = ImageProcessor()\n",
    "            results, droplet_segment_prelist = image_processor.process_image(image_path)\n",
    "\n",
    "            separated_tensors_list = []\n",
    "            for tensor in droplet_segment_prelist:\n",
    "                # If the tensor has more than one image, split it into individual tensors\n",
    "                if len(tensor.shape) == 4 and tensor.shape[0] > 1:\n",
    "                    separated_tensors_list.extend([tensor[i:i+1] for i in range(tensor.shape[0])])\n",
    "                else:\n",
    "                    separated_tensors_list.append(tensor)\n",
    "\n",
    "            droplet_segment_tensors_list.extend(separated_tensors_list)\n",
    "\n",
    "            # Check if droplet segments are detected\n",
    "            if results:\n",
    "                # Append results to Droplet Positions and Cell Counts for the current frame\n",
    "                frame_results = []\n",
    "                for result in results:\n",
    "                    frame_results.append([result[\"x_coordinate\"], result[\"cell_count\"]])\n",
    "\n",
    "                # Append results for the current frame to the overall list\n",
    "                all_results.append({f\"frame_{filename[:-4]}\": frame_results})\n",
    "            else:\n",
    "                print(f\"No droplet segments detected in {filename}. Skipping.\")\n",
    "\n",
    "    # Create JSON structure with frames sorted numerically\n",
    "    json_output = {}\n",
    "    for result in sorted(all_results, key=lambda x: int(list(x.keys())[0].split(\"_\")[1])):\n",
    "        json_output.update(result)\n",
    "\n",
    "    save_path = \"droplet_segment_tensors.pt\"\n",
    "    torch.save(droplet_segment_tensors_list, save_path)\n",
    "    print(f\"All droplet_segment_tensors saved to {save_path}\")\n",
    "\n",
    "    # Write JSON to file\n",
    "    output_file_path = os.path.join(outputPath, \"output.json\")\n",
    "    with open(output_file_path, 'w') as json_file:\n",
    "        json.dump(json_output, json_file, indent=2)\n",
    "\n",
    "    print(f\"JSON output written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELEN0016",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
